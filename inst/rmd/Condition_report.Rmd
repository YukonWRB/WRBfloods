---
title: "`r params$report_name`"
subtitle: "`r paste0(format(Sys.Date(), '%B %e'),', ', lubridate::year(Sys.Date()), ' at ', lubridate::hour(as.POSIXct(format((Sys.time()), tz='America/Whitehorse'))), ':00')`"
date: 
output: 
  word_document:
      reference_docx: style_template.docx
params:
  stations: stations
  report_name: report_name
  extra_years: extra_years
  image_path: image_path
  report_type: report_type
  level_zoom: level_zoom
  zoom_days: zoom_days
  meteogram: meteogram
---

```{r setup, include=FALSE}
#Normally there would not be a function call in a package, but these packages don't call nicely if they're not loaded.
knitr::opts_chunk$set(echo = TRUE)
library(tidyhydat.ws)
```

```{r Get station data, echo=FALSE, results='asis', message=FALSE, warning=FALSE}

#Make vectors of links to stations and of near/affected communities for later use
links <- vector() #make it to fill it next
community <- vector()
for (i in stations){
  newlink <- dplyr::filter(data$spatial_stns, `WSC ID` == i)$Link
  newcommunity <- dplyr::filter(data$spatial_stns, `WSC ID`==i)$`nrst community`
  links <- c(links, newlink)
  community <- c(community, newcommunity)
}

levelDataList <- list()
levelInfo <- list()
  
if (report_type %in% c("Both", "Level", "both", "level")){
    #parse out the extra years if requested
    if (is.null(extra_years)==FALSE){
      years <- data.frame(data=extra_years)
      years <- tidyr::separate(years, col=data, into=c("station","years"), sep=":")
    } else {
      years <- data.frame()
    }
  
  for(i in stations) {
    
    #tryCatch special here: the error function was not creating any output, so the error data.frames are created here. If successful, it is overwritten in the for loop, otherwise the error output is already created for each i
    tbl <- data.frame(
      `Station name` = if(is.na(tidyhydat::hy_stations(i)$STATION_NUMBER[1])==FALSE){stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME)} else{paste0(i, " DOES NOT EXIST")},
      ID = i,
      `Start year` = NA,
      `Today percent historic` = NA,
      Level = NA,
      `Level masl` = NA,
      Yesterday = NA,
      `24 hr change` = NA,
      `Two days ago` = NA,
      `Three days ago` = NA,
      `72 hr change` = NA,
      `Four days ago` = NA,
      `Five days ago` = NA,
      `Six days ago` = NA,
      `One week ago` = NA,
      `One week change` = NA,
      `Datum elevation` = NA
    )
    
    levelData <- data.frame() #Created to standardize the eventual output of this code block
    tryCatch ({
      #Get the level data
      if (is.null(extra_years)==FALSE & i %in% years$station==TRUE){
        levelData <- utils_level_data(
        station_number = i,
        select_years = unlist(strsplit(paste0(lubridate::year(Sys.Date()), ",", subset(years, station == i, select=years)[1,]), ",")),
        level_zoom = TRUE
      )
      } else{
        levelData <- utils_level_data(
        station_number = i,
        select_years = lubridate::year(Sys.Date()),
        level_zoom = TRUE
      )
      }
      
      datum_na <- is.na(as.numeric(dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(i)[,4]))))
      
      #Level data processing
      if (datum_na==TRUE) {
        startYearLevel <- min(lubridate::year(levelData$tidyData[[1]]$Date), na.rm = T)
        todayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        todayLevelmasl <- NA
        todayLevelPerc <- round(levelData$tidyData[[3]]$prctile[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())], 1)
        yesterdayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 1) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        twodayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 2) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        threedayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 3) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fourdayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 4) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fivedayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 5) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        sixdayLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 6) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        weekLevel <- levelData$tidyData[[3]]$Level[levelData$tidyData[[3]]$Date == (Sys.Date() - 7) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        
        tbl <- data.frame(
          `Station name` = stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME),
          ID = i,
          `Start year` = startYearLevel,
          `Today percent historic` = todayLevelPerc,
          `Level m`= todayLevel,
          `Level masl` = todayLevelmasl,
          Yesterday = yesterdayLevel,
          `24 hr change cm` = (todayLevel - yesterdayLevel)*100,
          `Two days ago` = twodayLevel,
          `Three days ago` = threedayLevel,
          `72 hr change cm` = (todayLevel - threedayLevel)*100,
          `Four days ago` = fourdayLevel,
          `Five days ago` = fivedayLevel,
          `Six days ago` = sixdayLevel,
          `One week ago` = weekLevel,
          `One week change cm` = (todayLevel - weekLevel)*100,
          `Datum elevation m` = as.numeric(dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(i)[,4])))
        )
      } else {
        startYearLevel <- min(lubridate::year(levelData$tidyData[[1]]$Date), na.rm = T)
        todayLevel <- levelData$tidyData[[3]]$`Level`[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        todayLevelmasl <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        todayLevelPerc <- round(levelData$tidyData[[3]]$prctile[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())], 1)
        yesterdayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 1) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        twodayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 2) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        threedayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 3) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fourdayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 4) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fivedayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 5) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        sixdayLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 6) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        weekLevel <- levelData$tidyData[[3]]$`Level masl`[levelData$tidyData[[3]]$Date == (Sys.Date() - 7) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        
        tbl <- data.frame(
          `Station name` = stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME),
          ID = i,
          `Start year` = startYearLevel,
          `Today percent historic` = todayLevelPerc,
          `Level m`= todayLevel,
          `Level masl` = todayLevelmasl,
          Yesterday = yesterdayLevel,
          `24 hr change cm` = (todayLevelmasl - yesterdayLevel)*100,
          `Two days ago` = twodayLevel,
          `Three days ago` = threedayLevel,
          `72 hr change cm` = (todayLevelmasl - threedayLevel)*100,
          `Four days ago` = fourdayLevel,
          `Five days ago` = fivedayLevel,
          `Six days ago` = sixdayLevel,
          `One week ago` = weekLevel,
          `One week change cm` = (todayLevelmasl - weekLevel)*100,
          `Datum elevation m` = as.numeric(dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(i)[,4])))
        )
      }
      
      #next few lines calculate where we're at for return periods
      if (i %in% data$return_periods$ID==TRUE) {
        
        if (datum_na == FALSE){
          levelConvert <- dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(i)[,4]))
          stn <- dplyr::filter(data$return_periods, ID == i) %>% purrr::map_if(is.numeric, ~.+levelConvert) #modify the return intervals with the same datum as the database
        } else {
          stn <- dplyr::filter(data$return_periods, ID == i)
        }

        tbl$`Current return period` <- 
          if (todayLevel < stn$twoyear) "<2 year" 
          else if (todayLevel < stn$fiveyear) "2 to 5 year" 
          else if (todaylevel < stn$tenyear) "5 to 10 year" 
          else if (todayLevel < stn$twentyyear) "10 to 20 year" 
          else if (todayLevel < stn$fiftyyear) "20 to 50 year" 
          else if (todayLevel < stn$onehundredyear) "50 to 100 year" 
          else if (todayLevel < stn$twohundredyear) "100 to 200 year" 
          else if (todayLevel > stn$twohundredyear & is.na(stn$fivehundredyear)) "> 200 year" 
          else if (todayLevel < stn$fivehundredyear) "200 to 500 year" 
          else if (todayLevel > stn$fivehundredyear & is.na(stn$thousandyear)) ">500 year"
          else if (todayLevel < stn$thousandyear) "500 to 1000 year"
          else if (todayLevel > stn$thousandyear) ">1000 year"
      } else {
        "NA"
      }
      
      levelInfo[[i]] <- tbl #add each station information to a list, later made into a table
    }, error=function(e) {}
    ) #End of tryCatch for station existence
    levelInfo[[i]] <- tbl #add each station information to a list, later made into a table
    levelDataList[[i]] <- levelData
    
  } #End of LEVEL for loop
}# End of if "level" or "both" selected statement


# Get flow data in two lists
flowDataList <- list()
flowInfo <- list()
if (report_type %in% c("Both", "Flow", "both", "flow")){
  #parse out the extra years if requested
  if (is.null(extra_years)==FALSE){
    years <- data.frame(data=extra_years)
    years <- tidyr::separate(years, col=data, into=c("station","years"), sep=":")
  } else {
    years <- data.frame()
  }
    
  for(i in stations) {
    station_info <- tidyhydat::hy_stations(i)
    #make the table for all stations (even lakes) so that start year information can be extracted in order when making the station info table later.
       tbl <- data.frame( 
        `Station name` = if(is.na(tidyhydat::hy_stations(i)$STATION_NUMBER[1])==FALSE){stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME)} else {paste0(i, " DOES NOT EXIST")},
        ID = i,
        `Start year flow` = NA,
        `Current flow`= 0.0001, #this is a number so that lake stations can be removed after.
        `Current percent historic` = NA,
        Yesterday = NA,
        `24 hr change` = NA,
        `Two days ago` = NA,
        `Three days ago` = NA,
        `72 hr change` = NA,
        `Four days ago` = NA,
        `Five days ago` = NA,
        `Six days ago` = NA,
        `One week ago` = NA,
        `One week change` = NA
      )    
    
    if (stringr::str_detect(station_info$STATION_NAME, "LAKE")==FALSE | stringr::str_detect(station_info$STATION_NAME, "RIVER")==TRUE){ #Lakes don't have flow measurements, but sometimes LAKE is mentioned when describing the river location

      tbl$Current.flow <- NA #Overwrite 0.0001 so that the reader knows that a station could/should have flow but does not
      
      flowData <- data.frame() #Created to standardize the eventual output of this code block
      tryCatch ({
        #Get the Flow data
        if (is.null(extra_years)==FALSE & i %in% years$station==TRUE){
          flowData <- utils_flow_data(
            station_number = i,
            select_years = unlist(strsplit(paste0(lubridate::year(Sys.Date()), ",", subset(years, station == i, select=years)[1,]), ",")),
            flow_zoom = TRUE
          )
        } else {
          flowData <- utils_flow_data(
            station_number = i,
            select_years = lubridate::year(Sys.Date()),
            flow_zoom = TRUE
          )
        }
        

        #Flow data processing
        startYearFlow <-
          min(lubridate::year(flowData$tidyData[[1]]$Date), na.rm = T)
        todayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == Sys.Date() & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        todayFlowPerc <- flowData$tidyData[[3]]$prctile[flowData$tidyData[[3]]$Date == Sys.Date() & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        yesterdayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 1) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        twodayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 2) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        threedayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 3) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fourdayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 4) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        fivedayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 5) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        sixdayFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 6) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        weekFlow <- flowData$tidyData[[3]]$Value[flowData$tidyData[[3]]$Date == (Sys.Date() - 7) & flowData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
        
        tbl <- data.frame(
          `Station name` = stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME),
          ID = i,
          `Start year flow` = startYearFlow,
          `Current flow` = todayFlow,
          `Current percent historic` = todayFlowPerc,
          Yesterday = yesterdayFlow,
          `24 hr change` = todayFlow - yesterdayFlow,
          `Two days ago` = twodayFlow,
          `Three days ago` = threedayFlow,
          `72 hr change` = todayFlow - threedayFlow,
          `Four days ago` = fourdayFlow,
          `Five days ago` = fivedayFlow,
          `Six days ago` = sixdayFlow,
          `One week ago` = weekFlow,
          `One week change` = todayFlow - weekFlow
        )
      }, error = function(e) {}
      ) #End of tryCatch for station existence
    } #End of loop that runs only if it's not a lake
      flowInfo[[i]] <- tbl #add each station information to a list, later made into a table
      flowDataList[[i]] <- flowData    
  } #End of FLOW for loop
}# End of if "flow" or "both" selected statement

```

```{r Compile station info, echo=FALSE, results='asis', message=FALSE}

stationInfo <- lapply(stations, function(x) dplyr::bind_cols(tidyhydat::hy_stations(x)[c(2,1,7,8)], if(nrow(dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(x)[,3])))==1) dplyr::slice_tail(as.data.frame(tidyhydat::hy_stn_datum_conv(x)[,3])) else (data.frame(DATUM_TO="Local datum")))) %>%
  purrr::reduce(dplyr::bind_rows)

levelStart <- dplyr::bind_rows(levelInfo)[3] #vector of start years

if (report_type %in% c("Both", "Flow", "both", "flow")){
  flowStart <- dplyr::bind_rows(flowInfo)[3] #vector of start years only if necessary
}

starts <- vector()
for (i in 1:nrow(levelStart)){
  if (report_type %in% c("Both", "Flow", "both", "flow")){
    x <- paste0("Level: ", levelStart[i,], " Flow: ", flowStart[i,])
    starts <- c(starts, x)
    starts <- gsub(" Flow:", " <br> Flow:", starts) #inserts a line break so level/flow end up on two lines
  } else {
    x <- paste0("Level: ", levelStart[i,])
    starts <- c(starts, x)
  }
}

stationInfo$`Start year` <- starts

stationInfo$links <- links #bring in the links created in earlier code chunk

stationInfo$STATION_NAME <- stringr::str_to_title(stationInfo$STATION_NAME) #remove ALL CAPS

stationInfo$Station <- paste0(stationInfo$STATION_NAME, " ([", stationInfo$STATION_NUMBER, "](", stationInfo$links, "))")

stationInfo <- stationInfo[c(8,6,3,4,5)]

stationInfo <- plyr::rename(stationInfo, c("LATITUDE"="Latitude", "LONGITUDE"="Longitude", "DATUM_TO"="Datum"))

#shrink the datum names
sub <- gsub("APPROXIMATE GEODETIC SURVEY OF CANADA DATUM", "CGVD28 (approximate)", stationInfo$Datum)
sub <- gsub("GEODETIC SURVEY OF CANADA DATUM", "CGVD28 (assumed)", sub)
sub <- gsub("CANADIAN GEODETIC VERTICAL DATUM 2013:EPOCH2010", "CGVD2013:2010", sub)
sub <- gsub("CANADIAN GEODETIC VERTICAL DATUM 1928", "CGVD28", sub)
stationInfo$Datum <- gsub("Local datum", "Local datum", sub)
```

```{r Get Precip data, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

#Get the links from the web, turn it into a usable table
htmlcode <- xml2::read_html("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/") #6 hour products for first day
nodes <- rvest::html_elements(htmlcode,xpath='//*[contains(@href, ".dbf")]') %>%
  rvest::html_attr("href")
dbf6 <- as.data.frame(as.character(nodes))
names(dbf6) <- "link"
dbf6 <- dbf6 %>% 
  dplyr::mutate(watershed = substr(link, 65,66), #Create watershed column 
                cutoff = substr(link, 25, 28), #find the cutoff time
                datetime = substr(link, 50,59)) #find the valid date/time

htmlcode <- xml2::read_html("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/24/") #24 hour products for subsequent days
nodes <- rvest::html_elements(htmlcode,xpath='//*[contains(@href, ".dbf")]') %>%
  rvest::html_attr("href")
dbf24 <- as.data.frame(as.character(nodes))
names(dbf24) <- "link"
dbf24 <- dbf24 %>% 
  dplyr::mutate(watershed = substr(link, 65,66), #Create watershed column 
                cutoff = substr(link, 25, 28), #find the cutoff time
                datetime = substr(link, 50,59)) #find the valid date/time


watersheds <- unique(substr(stations, 1,2)) #determine in which watershed(s) we want to look

first6 <- list() #lists created here to populate in for loop
subsequent <- list()

for (i in watersheds){
  
  #FIRST use 6 hour data for the first 24 hour period
  first <- dplyr::filter(dbf6, watershed==i, cutoff=="0100") %>% dplyr::arrange(desc(datetime)) #uses cutoff 0100 to get as recent data as possible.
  
  validdatetime <- as.POSIXct(first$datetime[1], format="%Y%m%d%H", tz="UTC")
  
  temp <- tempfile(fileext=".dbf")
  R.utils::downloadFile(paste0("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/CMC_HRDPA_WATERSHED-006-0100cutoff_SFC_0_ps2.5km_", first$datetime[1], "_000_", i, ".dbf"), temp) #sadly overwrite=TRUE does not work!
  first6[[i]] <- foreign::read.dbf(temp)
  unlink(temp)
  
  #THEN get the next 27 6 hour periods
  for (j in 1:27) {
    subsequent6 <- dplyr::filter(dbf6, watershed==i, cutoff=="0700") %>% dplyr::arrange(desc(datetime)) #uses cutoff 0700 from here on because we might as well use the more accurate data
    
    temp <- tempfile(fileext=".dbf")
    R.utils::downloadFile(paste0("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/CMC_HRDPA_WATERSHED-006-0700cutoff_SFC_0_ps2.5km_", subsequent6$datetime[j], "_000_", i, ".dbf"), temp)
    subsequent[[i]][[j]] <- foreign::read.dbf(temp)
    unlink(temp)
  }
  
}

first6 <- subset(data.table::rbindlist(first6), Station %in% stations) #combine the stations to one data.frame

all6hr <- list(first6) #make a list and insert the first element

for (i in 2:28){ #populate the rest of the list so we can bind_rows to those data.frames later
  all6hr[[i]] <- data.frame()
}

for (i in 1:length(subsequent)){ #bind it all together to make a simple list of 28.
  for (j in 2:28){
    all6hr[[j]] <- subset(dplyr::bind_rows(all6hr[[j]], subsequent[[i]][[j-1]]), Station %in% stations)
  }
}

```

```{r Levels table, echo=FALSE, results='asis', message=FALSE}

if (report_type %in% c("Both", "Level", "both", "level") & length(levelInfo) > 0){
  cat("  \n# Summary of levels and level changes \n")
  levelTable <- dplyr::bind_rows(levelInfo)[c(5, 6, 4, 8, 11, 18)]
  levelTable <-  dplyr::bind_cols(stationInfo[,1], levelTable) #add in the pre-made column with links embedded.
  names(levelTable) <- gsub("\\.", " ", names(levelTable))
  names(levelTable) <- gsub("X", "", names(levelTable))
  
  names(levelTable) <- gsub("masl", "(masl)*", names(levelTable))
  names(levelTable) <- gsub("cm", "(cm)", names(levelTable))
  names(levelTable) <- gsub("\\sm", " (m)", names(levelTable))
  
  colnames(levelTable) <- c("Station name (number)", "Current level (m)", "Current level (masl)", "Current percent historic", "24 hr change (cm)", "72 hr change (cm)", "Current return period")
  
  levelTable$`24 hr change (cm)` <- round(levelTable$`24 hr change (cm)`,1)
  levelTable$`72 hr change (cm)` <- round(levelTable$`72 hr change (cm)`,1)
  
  knitr::kable(levelTable, digits=2)
}
```



```{r Flows table, echo=FALSE, results='asis', message=FALSE}

if (report_type %in% c("Both", "Flow", "both", "flow") & length(flowInfo) > 0){
  cat( "  \n# Summary of flows and flow changes in m^3^/s  \n")
  
  flowTable <-  dplyr::bind_rows(flowInfo) %>% 
    dplyr::bind_cols(stationInfo[,1], .)#add in the pre-made column with links embedded.
    
  flowTable <- dplyr::filter(flowTable, Current.flow != 0.0001)[c(1, 5, 6, 8, 11, 16)]
  
  names(flowTable) <- gsub("\\.", " ", names(flowTable))
  names(flowTable) <- gsub("X", "", names(flowTable))
  
  flowTable$`Current percent historic` <- round(flowTable$`Current percent historic`, 0)
  
  print(knitr::kable(flowTable, digits=1))
  
  if (NA %in% stringr::str_detect(flowTable$`Current flow`, "NA")){
    cat("**NOTE**: NA values mean that there is no current flow measurement. Some stations may have historical flow records; refer to the next table for record length information.")
  }
}
```

<br>

# Accumulated Precipitation Above Stations

```{r Precip table, echo=FALSE, results='asis', message=FALSE}

precip12hr <- all6hr[[1]]$PR_mm + all6hr[[2]]$PR_mm

precip24hr <- precip12hr + all6hr[[3]]$PR_mm + all6hr[[4]]$PR_mm

precip48hr <- 0
for (i in 1:8){
  precip48hr <- all6hr[[i]]$PR_mm + precip48hr
}

precip72hr <- 0
for (i in 1:12){
  precip72hr <- all6hr[[i]]$PR_mm + precip72hr
}

precip96hr <- 0
for(i in 1:16){
  precip96hr <- all6hr[[i]]$PR_mm + precip96hr
}

precip1wk <- 0
  for (i in 1:28){
   precip1wk <- all6hr[[i]]$PR_mm + precip1wk
}

precipTable <- data.frame(all6hr[[1]]$Station, stringr::str_to_title(all6hr[[1]]$StationNam), precip12hr, precip24hr, precip48hr, precip72hr, precip96hr, precip1wk)
colnames(precipTable) <- c("Station code", "Station name", "12 hours", "One day", "Two days", "Three days", "Four days", "One week")
  
  knitr::kable(precipTable, digits=3, caption=paste0("Accumulated precipitation (mm of water) prior to ", validdatetime-7*60*60, " Yukon Time for selected stations."))
```

\newpage

# Hydrometric Station Data and Graphs

Water level and/or flow data is pulled from [historical](https://wateroffice.ec.gc.ca/mainmenu/historical_data_index_e.html) and [real-time](https://wateroffice.ec.gc.ca/mainmenu/real_time_data_index_e.html) hydrometric data published by the Government of Canada. Return intervals are plotted where available, represting two, ten, one hundred and two hundred year return intervals. All datum elevations are in reference to the Canadian Geodetic Vertical Datum of 1928 (CGVD28).

```{r Station info table, echo=FALSE, results='asis', message=FALSE}
datums <- unique(stationInfo$Datum)

#Make a table with the necessary notes and their associated datums
note_table <- data.frame(datum = c("CGVD28 (approximate)", 
             "CGVD28 (assumed)", 
             "CGVD2013:2010", 
             "CGVD28", 
             "Local datum"), 
           note = c("Derived from a digital elevation model with vertical datum in Canadian Geodetic Vertical Datum of 1928 ([CGVD28](https://cgrsc.ca/resources/geodetic-control-networks/vertical-control-networks/)); uncertainty in accordance with the [Canadian Digital Elevation Model](https://ftp.maps.canada.ca/pub/nrcan_rncan/elevation/cdem_mnec/doc/CDEM_product_specs.pdf).", 
             "Vertical datum not specified in historical records, but implementation date indicates use of [(CGVD28](https://cgrsc.ca/resources/geodetic-control-networks/vertical-control-networks/)).",
             "Vertical datum in Canadian Geodetic Vertical Datum of 2013, epoch 2010 [(CGVD2013:2010](https://cgrsc.ca/resources/geodetic-control-networks/vertical-control-networks/)).",
             "Vertical datum in Canadian Geodetic Vertical Datum of 1928 [(CGVD28](https://cgrsc.ca/resources/geodetic-control-networks/vertical-control-networks/)).", 
             "Arbitrary datum relative to station or other nearby fixed point."))


#Add a number to each datum and populate notes with the required notes
notes <- vector()
for (i in datums){
  stationInfo$Datum <- gsub(i, paste0(i, " [", which(datums==i), "]"), stationInfo$Datum, fixed=TRUE)
  notes <- c(notes, paste0("[", which(datums==i), "] ", dplyr::filter(note_table, datum==i)[,2]))
}



knitr::kable(stationInfo, digits=2, caption="These are the stations contained in this report:")

cat("**Notes:**  \n")
for (i in 1:length(notes)){
  cat(notes[[i]], "  \n")
}
```

\newpage

```{r Generate plots, echo=FALSE, fig.height=4.2, fig.width=7.5, message=FALSE, warning=FALSE, results='asis'}

for(i in stations) {
  n <- which(stations==i)
  station_info <- tidyhydat::hy_stations(i)
  if(is.na(station_info$STATION_NUMBER[1])==FALSE){
    tryCatch ( {
      cat("  \n## ", stringr::str_to_title(station_info$STATION_NAME)," (station ", i,")  \n")
      
      if (report_type %in% c("Both", "Level", "both", "level")){
        tryCatch ({
          
          cat("  \n### Level  \n")
          
          #Level data plotting
          levelPlot <- utils_daily_level_plot(station_number = i,
                                        complete_year = levelDataList[[n]][[1]][[2]],
                                        plot_years_df = levelDataList[[n]][[1]][[3]],
                                        dummy_year_df = levelDataList[[n]][[1]][[4]])
          print(levelPlot)
          cat("  \n")
          
          if (level_zoom == TRUE){ #Plot zoomed-in level data
            
            cat("  \n### Level (last", zoom_days, " days) \n")
            zoomPlot <- utils_zoom_level_plot(station_number = i,
                                        complete_year = levelDataList[[n]][[1]][[2]],
                                        plot_years_df = levelDataList[[n]][[1]][[3]],
                                        dummy_year_df = levelDataList[[n]][[1]][[4]],
                                        zoom_data = levelDataList[[n]][[2]],
                                        zoom_days = zoom_days)
            tryCatch({
              print(zoomPlot)
              cat("  \n")
            },
            error=function(e) {cat("  \n There are no recent levels in the WSC database or the time-series could not be processed. \n")})

          }
        },
        error=function(e) {})
      } # End of if "level" or "both" selected statement

      
      if (stringr::str_detect(station_info$STATION_NAME, "LAKE")==FALSE | stringr::str_detect(station_info$STATION_NAME, "RIVER")==TRUE){ #Lakes don't have flow measurements, but sometimes LAKE is mentioned when describing the river location
        if (report_type %in% c("Both", "Flow", "both", "flow")){
          tryCatch ({

            cat("  \n### Flow  \n")

            #Flow data plotting
            flowPlot <- utils_daily_flow_plot(station_number = i,
                                  complete_year = flowDataList[[n]][[1]][[2]],
                                  plot_years_df = flowDataList[[n]][[1]][[3]],
                                  dummy_year_df = flowDataList[[n]][[1]][[4]])
            print(flowPlot)
            cat("  \n\n\\newpage\n\n")
            },
          error = function(e) {
            cat("  \n Station ", i, " does not appear to have real-time flow (discharge) data right now. \n")
            cat("  \n\\newpage\n\n")})
        } #End of if flow or both selected
      } #End of if statement that is "LAKE" dependent
    }, 
    error= function(e) {})
    
  } else {#End of if loop
   cat("  \n\\newpage\n\n") 
   cat("## ", tidyhydat::hy_stations(i)$STATION_NAME, " Station ", i)
   cat("  \n Station ", i, " could not be found in the WSC tidyhydat database.\n")
   cat("  \n\\newpage\n\n")

  }
} #End of For loop

cat("  \n")
```

# Recent precipitation

The following images represent precipitation in and around Yukon. Each image integrates precipitation (from observations and remote sensing) over the 24 hours prior to the image's valid date/time (Yukon time).

```{r HRDPA, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4.15, fig.width=7, results='asis'}

#using the imager::load.image method instead of the standard knitr::include_graphics because include_graphics just won't work with the network drive. This used to be necessary but stopped working for unknown reason. 
# tryCatch({
#   setwd("//cs-fs2/cs-data/PS/Weather/WeatherFiles/Common/Grads_images/sumRDPA/hrdpa/24/")
#   wxfiles<- list.files(pattern="\\.png$")
#   par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
# 
#   imager::load.image(wxfiles[length(wxfiles)]) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)
# 
#   cat("  \n  \n  ")
#   imager::load.image(wxfiles[length(wxfiles)-2]) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)
# }, error=function(e) {
#   cat("HRDPA images cannot be fetched from the YG server. Are you on a different network?  \n  \n  ")
# })

tryCatch({
  wxfiles<- list.files("//cs-fs2/cs-data/PS/Weather/WeatherFiles/Common/Grads_images/sumRDPA/hrdpa/24/", pattern="\\.png$")
  par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
  
  imager::load.image(paste0("//cs-fs2/cs-data/PS/Weather/WeatherFiles/Common/Grads_images/sumRDPA/hrdpa/24/", wxfiles[length(wxfiles)])) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)
  
  cat("  \n  \n  ")
  imager::load.image(paste0("//cs-fs2/cs-data/PS/Weather/WeatherFiles/Common/Grads_images/sumRDPA/hrdpa/24/", wxfiles[length(wxfiles)-2])) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)
}, error=function(e) {
  cat("HRDPA images cannot be fetched from the YG server. Are you on a different network?  \n  \n  ")
})


```

```{r Meteograms, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8.8, fig.width=7.5, results='asis'}
if (meteogram==TRUE){
  cat("  \n# Weather forecast(s)  \n")

  stationCoords <- sf::st_as_sf(stationInfo, coords=c("Longitude", "Latitude"), crs=4326) %>% 
    sf::st_set_crs(4326) %>%
    sf::st_transform(3579)
  
  meteoStns <- sf::st_as_sf(dplyr::filter(data$spatial_stns[,c(1,3,7,8)], Type == "Meteogram"), coords=c("Longitude", "Latitude"), crs=4326) %>%
    sf::st_set_crs(4326) %>%
    sf::st_transform(3579)
  
  buffers <- sf::st_buffer(stationCoords, dist = 120000) #150 km buffer
  
  meteos <- as.data.frame(meteoStns[lengths(sf::st_intersects(meteoStns, buffers)) > 0,]) #subset meteoStns according to the meteoStns that return TRUE for intersection
  
  
# plot <- ggplot() +
#   geom_sf(data=stationCoords, col="red") +
#   geom_sf(data=meteoStns, col="blue") +
#   geom_sf(data=buffers, fill=NA) +
#   theme_minimal()

  dateTimeUTC <- format(Sys.time(), "%Y%m%d")

  par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
  
  for (i in meteos$`Meteogram code`) {
    cat("  \n")
    imager::load.image(paste0("https://collaboration.cmc.ec.gc.ca/cmc/ensemble/data2/combine/images/", dateTimeUTC, "00_054@007_E1_", i, "_I_NAEFS@EPSGRAMS_tt@surf@nt@pr@ws@surf_360.png")) %>% plot(axes=FALSE)
    cat("  \n")
  }
}

```

\newpage

```{r Fixed camera images, eval=TRUE, echo=FALSE, fig.height=4, fig.width=7, message=FALSE, warning=FALSE, fig.height=4, fig.width=7, results='asis'}
#This section will contain auto-generated images, selected based on the stations(s) selected.

tryCatch({
  images <- XML::readHTMLTable(httr::content(httr::GET("https://collaboration.cmc.ec.gc.ca/cmc/hydrometric_additionalData/FieldData/YT/", config=httr::authenticate(Sys.getenv("ECCCUSER"), Sys.getenv("ECCCPASS"))), "text"))[[1]]
  images <- images[c(-1,-2),-1] #first two rows are not files and first column is nothing
  images <- images[grep(paste(stations, collapse="|"), images$Name), ] #subset only the images that match stations requested
  images <- images %>% dplyr::filter((as.POSIXct(images[,2], tz="UTC")-7*60*60) >= Sys.Date()-7) #Subsets only images < 7 days old.
  
  if (nrow(images)>=1){
    images <- dplyr::arrange(images, desc(images$`Last modified`)) %>% dplyr::mutate(Station = substr(Name, 1,7))  #Sort by descending, make column for station
    
    par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
    cat("# Fixed Camera Images")
    for (i in unique(images$Station)){
      last_image <- dplyr::filter(images, Station==i)[1,]
      cat("  \n### ", stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME), "(", substr(as.character(as.POSIXct(last_image[,2], tz="UTC")-7*60*60), 1, 16), "Yukon Time)  \n")
      
      
      temp <- paste0(tempfile(),".jpg")
      R.utils::downloadFile(paste0("https://collaboration.cmc.ec.gc.ca/cmc/hydrometric_additionalData/FieldData/YT/", last_image[,1]), temp, username=Sys.getenv("ECCCUSER"), password = Sys.getenv("ECCCPASS"))
      imager::load.image(paste0(temp)) %>% plot(axes=FALSE)
      unlink(temp)
      cat("  \n")
    }
  }
}, error=function(e){cat("  \nFetching images failed. Do you have login credentials in your .Renviron file? Check the function notes for details.")})


```

```{r User select images, echo=FALSE, fig.height=4, fig.width=7, message=FALSE, warning=FALSE, results='asis'}
#This section will contain images in a folder specified by the user, if applicable
if (is.null(image_path)!=TRUE){
  cat("  \n# Other Images  \n")
  custom_images <- list.files(path-image_path)
  for (i in custom_images){
    imager::load.image(i) %>% plot(axes=FALSE)
    cat("  \n")
  }
}

```
