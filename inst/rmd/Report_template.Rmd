---
title: "`r params$report_name`"
subtitle: "`r paste0(format(Sys.Date(), '%B %d'),', ', lubridate::year(Sys.Date()))`"
date: 
output: 
  word_document:
      reference_docx: style_template.docx
params:
  stations: stations
  report_name: report_name
  extra_years: extra_years
  image_path: image_path
  report_type: report_type
  level_zoom: level_zoom
  zoom_days: zoom_days
  meteogram: meteogram
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyhydat)
library(tidyhydat.ws)
```

```{r Get station data, echo=FALSE, results='asis', message=FALSE, warning=FALSE}
levelDataList <- list() #these are not with the if statements that use them because their existence is necessary no matter what later on.
levelInfo <- list()
flowDataList <- list()
flowInfo <- list()

if (report_type %in% c("Both", "Level", "both", "level")){
  
    #parse out the extra years if requested
    if (is.null(extra_years)==FALSE){
      years <- data.frame(data=extra_years)
      years <- tidyr::separate(years, col=data, into=c("station","years"), sep=":")
    }
  
  for(i in stations) {
    
    #tryCatch special here: the error function was not creating any output, so the error data.frames are created here. If successful, it is overwritten in the for loop, otherwise the error output is already created for each i
    tbl <- data.frame(
      `Station name` = if(is.na(tidyhydat::hy_stations(i)$STATION_NUMBER[1])==FALSE){stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME)} else{paste0(i, " DOES NOT EXIST")},
      ID = i,
      `Start year` = NA,
      `Today percent historic` = NA,
      Today = NA,
      Yesterday = NA,
      `24 hr change` = NA,
      `Two days ago` = NA,
      `Three days ago` = NA,
      `72 hr change` = NA,
      `Four days ago` = NA,
      `Five days ago` = NA,
      `Six days ago` = NA,
      `One week ago` = NA,
      `One week change` = NA,
      `Datum elevation` = NA
    )
    
    levelData <- data.frame() #Created to standardize the eventual output of this code block
    tryCatch ({
      #Get the level data
      if (is.null(extra_years)==FALSE & i %in% years$station==TRUE){
        levelData <- daily_level_data(
        station_number = i,
        select_years = unlist(strsplit(paste0(lubridate::year(Sys.Date()), ",", subset(years, station == i, select=years)[1,]), ",")),
        level_zoom = TRUE
      )
      } else{
        levelData <- daily_level_data(
        station_number = i,
        select_years = lubridate::year(Sys.Date()),
        level_zoom = TRUE
      )
      }
      

      #Level data processing
      startYearLevel <-
        min(lubridate::year(levelData$tidyData[[1]]$Date), na.rm = T)
      todayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      todayLevelPerc <- round(levelData$tidyData[[3]]$prctile[levelData$tidyData[[3]]$Date == Sys.Date() & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())], 1)
      yesterdayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 1) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      twodayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 2) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      threedayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 3) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      fourdayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 4) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      fivedayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 5) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      sixdayLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 6) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      weekLevel <- levelData$tidyData[[3]]$Value[levelData$tidyData[[3]]$Date == (Sys.Date() - 7) & levelData$tidyData[[3]]$Year_Real == lubridate::year(Sys.Date())]
      
      tbl <- data.frame(
        `Station name` = stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME),
        ID = i,
        `Start year` = startYearLevel,
        `Today percent historic` = todayLevelPerc,
        Today = todayLevel,
        Yesterday = yesterdayLevel,
        `24 hr change` = todayLevel - yesterdayLevel,
        `Two days ago` = twodayLevel,
        `Three days ago` = threedayLevel,
        `72 hr change` = todayLevel - threedayLevel,
        `Four days ago` = fourdayLevel,
        `Five days ago` = fivedayLevel,
        `Six days ago` = sixdayLevel,
        `One week ago` = weekLevel,
        `One week change` = todayLevel - weekLevel,
        `Datum elevation` = as.numeric(tidyhydat::hy_stn_datum_conv(i)[1, 4])
      )
      levelInfo[[i]] <- tbl #add each station information to a list, later made into a table
    }, error=function(e) {}
    ) #End of tryCatch for station existence
    levelInfo[[i]] <- tbl #add each station information to a list, later made into a table
    levelDataList[[i]] <- levelData
    
    
  } #End of LEVEL for loop
}# End of if "level" or "both" selected statement


if (report_type %in% c("Both", "Flow", "both", "flow")){

  for(i in stations) {
    station_info <- tidyhydat::hy_stations(i)
    if (stringr::str_detect(station_info$STATION_NAME, "LAKE")==FALSE | stringr::str_detect(station_info$STATION_NAME, "RIVER")==TRUE){ #Lakes don't have flow measurements, but sometimes LAKE is mentioned when describing the river location
      
      tbl <- data.frame(
        `Station name` = if(is.na(tidyhydat::hy_stations(i)$STATION_NUMBER[1])==FALSE){stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME)} else{paste0(i, " DOES NOT EXIST")},
        ID = i,
        `Start year` = NA,
        `Today percent historic` = NA,
        Today = NA,
        Yesterday = NA,
        `24 hr change` = NA,
        `Two days ago` = NA,
        `Three days ago` = NA,
        `72 hr change` = NA,
        `Four days ago` = NA,
        `Five days ago` = NA,
        `Six days ago` = NA,
        `One week ago` = NA,
        `One week change` = NA
      )
      
      flowData <- data.frame() #Created to standardize the eventual output of this code block
      tryCatch ({
        #Get the Flow data
        flowData <- flow_data(
          station_number = i,
          extract_realtime = TRUE,
          select_years = lubridate::year(Sys.Date())
        )
        
        #Flow data processing
        startYearFlow <- min(lubridate::year(flowData[[1]]$Date), na.rm = T)
        todayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==Sys.Date()]
        todayFlowPerc <- round(flowData[[3]]$prctile[flowData[[3]]$Date==Sys.Date()],1)
        yesterdayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-1)]
        twodayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-2)]
        threedayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-3)]
        fourdayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-4)]
        fivedayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-5)]
        sixdayFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-6)]
        weekFlow <- flowData[[3]]$Value[flowData[[3]]$Date==(Sys.Date()-7)]
        
        tbl <- data.frame(
          `Station name` = stringr::str_to_title(tidyhydat::hy_stations(i)$STATION_NAME),
          ID = i,
          `Start year` = startYearFlow,
          `Today percent historic` = todayFlowPerc,
          Today = todayFlow,
          Yesterday = yesterdayFlow,
          `24 hr change` = todayFlow - yesterdayFlow,
          `Two days ago` = twodayFlow,
          `Three days ago` = threedayFlow,
          `72 hr change` = todayFlow - threedayFlow,
          `Four days ago` = fourdayFlow,
          `Five days ago` = fivedayFlow,
          `Six days ago` = sixdayFlow,
          `One week ago` = weekFlow,
          `One week change` = todayFlow - weekFlow
        )
      }, error = function(e) {}
      ) #End of tryCatch for station existence
      flowInfo[[i]] <- tbl #add each station information to a list, later made into a table
      flowDataList[[i]] <- flowData 
    }
  } #End of FLOW for loop
}# End of if "flow" or "both" selected statement

```

```{r Get Precip data, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

#Get the links from the web, turn it into a usable table
htmlcode <- xml2::read_html("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/") #6 hour products for first day
nodes <- rvest::html_elements(htmlcode,xpath='//*[contains(@href, ".dbf")]') %>%
  rvest::html_attr("href")
dbf6 <- as.data.frame(as.character(nodes))
names(dbf6) <- "link"
dbf6 <- dbf6 %>% 
  dplyr::mutate(watershed = substr(link, 65,66), #Create watershed column 
                cutoff = substr(link, 25, 28), #find the cutoff time
                datetime = substr(link, 50,59)) #find the valid date/time

htmlcode <- xml2::read_html("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/24/") #24 hour products for subsequent days
nodes <- rvest::html_elements(htmlcode,xpath='//*[contains(@href, ".dbf")]') %>%
  rvest::html_attr("href")
dbf24 <- as.data.frame(as.character(nodes))
names(dbf24) <- "link"
dbf24 <- dbf24 %>% 
  dplyr::mutate(watershed = substr(link, 65,66), #Create watershed column 
                cutoff = substr(link, 25, 28), #find the cutoff time
                datetime = substr(link, 50,59)) #find the valid date/time


watersheds <- unique(substr(stations, 1,2)) #determine in which watershed(s) we want to look

first6 <- list() #lists created here to populate in for loop
subsequent <- list()

for (i in watersheds){
  
  #FIRST use 6 hour data for the first 24 hour period
  first <- dplyr::filter(dbf6, watershed==i, cutoff=="0100") %>% dplyr::arrange(desc(datetime)) #uses cutoff 0100 to get as recent data as possible.
  
  validdatetime <- as.POSIXct(first$datetime[1], format="%Y%m%d%H", tz="UTC")
  
  temp <- tempfile(fileext=".dbf")
  R.utils::downloadFile(paste0("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/CMC_HRDPA_WATERSHED-006-0100cutoff_SFC_0_ps2.5km_", first$datetime[1], "_000_", i, ".dbf"), temp) #sadly overwrite=TRUE does not work!
  first6[[i]] <- foreign::read.dbf(temp)
  unlink(temp)
  
  #THEN get the next 27 6 hour periods
  for (j in 1:27) {
    subsequent6 <- dplyr::filter(dbf6, watershed==i, cutoff=="0700") %>% dplyr::arrange(desc(datetime)) #uses cutoff 0700 from here on because we might as well use the more accurate data
    
    temp <- tempfile(fileext=".dbf")
    R.utils::downloadFile(paste0("https://dd.weather.gc.ca/analysis/precip/hrdpa_watershed/shapefile/06/CMC_HRDPA_WATERSHED-006-0700cutoff_SFC_0_ps2.5km_", subsequent6$datetime[j], "_000_", i, ".dbf"), temp)
    subsequent[[i]][[j]] <- foreign::read.dbf(temp)
    unlink(temp)
  }
  
}

first6 <- subset(data.table::rbindlist(first6), Station %in% stations) #combine the stations to one data.frame

all6hr <- list(first6) #make a list and insert the first element

for (i in 2:28){ #populate the rest of the list so we can bind_rows to those data.frames later
  all6hr[[i]] <- data.frame()
}

for (i in 1:length(subsequent)){ #bind it all together to make a simple list of 28.
  for (j in 2:28){
    all6hr[[j]] <- subset(dplyr::bind_rows(all6hr[[j]], subsequent[[i]][[j-1]]), Station %in% stations)
  }
}

```

# Current Status and Observations

[Enter update here]

<br>

```{r Levels table, echo=FALSE, results='asis', message=FALSE}

if (report_type %in% c("Both", "Level", "both", "level") & length(levelInfo) > 0){
  cat("  \n# Summary of levels and level changes in meters  \n")
  levelTable <- dplyr::bind_rows(levelInfo)[c(1,3:5,7, 10, 15,16)]
  names(levelTable) <- gsub("\\.", " ", names(levelTable))
  names(levelTable) <- gsub("X", "", names(levelTable))
  
  knitr::kable(levelTable, digits=3)
}
```

```{r Flows table, echo=FALSE, results='asis', message=FALSE}

if (report_type %in% c("Both", "Flow", "both", "flow") & length(flowInfo) > 0){
  cat( "  \n# Summary of flows and flow changes in m^3^/s  \n")
  flowTable <- dplyr::bind_rows(flowInfo)[c(1,3:5,7, 10, 15)]
  names(flowTable) <- gsub("\\.", " ", names(flowTable))
  names(flowTable) <- gsub("X", "", names(flowTable))
  
  knitr::kable(flowTable, digits=3)
}
```

<br>

# Accumulated Precipitation Above Stations

```{r Precip table, echo=FALSE, results='asis', message=FALSE}

precip12hr <- all6hr[[1]]$PR_mm + all6hr[[2]]$PR_mm

precip24hr <- precip12hr + all6hr[[3]]$PR_mm + all6hr[[4]]$PR_mm

precip48hr <- 0
for (i in 1:8){
  precip48hr <- all6hr[[i]]$PR_mm + precip48hr
}

precip72hr <- 0
for (i in 1:12){
  precip72hr <- all6hr[[i]]$PR_mm + precip72hr
}

precip96hr <- 0
for(i in 1:16){
  precip96hr <- all6hr[[i]]$PR_mm + precip96hr
}

precip1wk <- 0
  for (i in 1:28){
   precip1wk <- all6hr[[i]]$PR_mm + precip1wk
}

precipTable <- data.frame(all6hr[[1]]$Station, stringr::str_to_title(all6hr[[1]]$StationNam), precip12hr, precip24hr, precip48hr, precip72hr, precip96hr, precip1wk)
colnames(precipTable) <- c("Station code", "Station name", "12 hours", "One day", "Two days", "Three days", "Four days", "One week")
  
  knitr::kable(precipTable, digits=3, caption=paste0("Accumulated precipitation (mm of water) prior to ", validdatetime-7*60*60, " Yukon Time for selected stations."))
```

\newpage

# Hydrometric Station Data and Graphs

Water level and/or flow data is pulled from [historical](https://wateroffice.ec.gc.ca/mainmenu/historical_data_index_e.html) and [real-time](https://wateroffice.ec.gc.ca/mainmenu/real_time_data_index_e.html) hydrometric data published by the Government of Canada. Return intervals are plotted where available, represting two, ten, one hundred and two hundred year return intervals. All datum elevations are in reference to the Canadian Geodetic Vertical Datum of 1928 (CGVD28).

```{r Station info table, echo=FALSE, results='asis', message=FALSE}

stationInfo <- lapply(stations, function(x) tidyhydat::hy_stations(x)[c(2,1,7,8)]) %>%
  purrr::reduce(dplyr::bind_rows) %>% 
  plyr::rename(c("STATION_NAME"="Station Name", "STATION_NUMBER"="ID", "LATITUDE"="Latitude", "LONGITUDE"="Longitude"))

stationInfo$`Station Name` <- stringr::str_to_title(stationInfo$`Station Name`)

knitr::kable(stationInfo, digits=3, caption="These are the stations contained in this report:")

```

\newpage

```{r Generate plots, echo=FALSE, fig.height=4.2, fig.width=7.5, message=FALSE, warning=FALSE, results='asis'}

for(i in stations) {
  n <- which(stations==i)
  station_info <- tidyhydat::hy_stations(i)
  if(is.na(station_info$STATION_NUMBER[1])==FALSE){
    tryCatch ( {
      cat("  \n## ", stringr::str_to_title(station_info$STATION_NAME)," (Station ", i,")  \n")
      
      if (report_type %in% c("Both", "Level", "both", "level")){
        tryCatch ({
          datum_na <- is.na(as.numeric(tidyhydat::hy_stn_datum_conv(i)[1,4])) #different axis text if no datum
          
          cat("  \n### Level  \n")
          
          #Level data plotting
          levelPlot <- daily_level_plot(station_number = i,
                                        complete_year = levelDataList[[n]][[1]][[2]],
                                        plot_years_df = levelDataList[[n]][[1]][[3]],
                                        dummy_year_df = levelDataList[[n]][[1]][[4]])
          print(levelPlot)
          cat("  \n")
          
          if (level_zoom == TRUE){ #Plot zoomed-in level data
            
            cat("  \n### Level (last", zoom_days, " days) \n")
            zoomPlot <- zoom_level_plot(station_number = i,
                                        complete_year = levelDataList[[n]][[1]][[2]],
                                        plot_years_df = levelDataList[[n]][[1]][[3]],
                                        dummy_year_df = levelDataList[[n]][[1]][[4]],
                                        zoom_data = levelDataList[[n]][[2]],
                                        zoom_days = zoom_days)
            tryCatch({
              print(zoomPlot)
              cat("  \n")
            },
            error=function(e) {cat("  \n There are no recent levels in the WSC database or the time-series could not be processed. \n")})

          }
        },
        error=function(e) {})
      } # End of if "level" or "both" selected statement

      
      if (stringr::str_detect(station_info$STATION_NAME, "LAKE")==FALSE | stringr::str_detect(station_info$STATION_NAME, "RIVER")==TRUE){ #Lakes don't have flow measurements, but sometimes LAKE is mentioned when describing the river location
        if (report_type %in% c("Both", "Flow", "both", "flow")){
          tryCatch ({

            cat("  \n### Flow  \n")

            #Flow data plotting
            flowPlot <- flow_plot(station_number = i,
                                  complete_year = flowDataList[[n]][[2]],
                                  plot_years_df = flowDataList[[n]][[3]],
                                  dummy_year_df = flowDataList[[n]][[4]])
            print(flowPlot)
            cat("  \n\n\\newpage\n\n")
            },
          error = function(e) {
            cat("  \n Station ", i, " does not appear to have real-time flow (discharge) data right now. \n")
            cat("  \n\\newpage\n\n")})
        } #End of if flow or both selected
      } #End of if statement that is "LAKE" dependent
    }, 
    error= function(e) {})
    
  } else {#End of if loop
   cat("  \n\\newpage\n\n") 
   cat("## ", tidyhydat::hy_stations(i)$STATION_NAME, " Station ", i)
   cat("  \n Station ", i, " could not be found in the WSC tidyhydat database.\n")
   cat("  \n\\newpage\n\n")

  }
} #End of For loop

cat("  \n")
```

# Recent precipitation

The following images represent precipitation in and around Yukon. Each image integrates precipitation (from observations and remote sensing) over the 24 hours prior to the image's valid date/time (Yukon time).

```{r HRDPA, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4.15, fig.width=7, results='asis'}

#using the imager::load.image method instead of the standard knitr::include_graphics because include_graphics just won't work with the network drive.

setwd("//cs-fs2/cs-data/PS/Weather/WeatherFiles/Common/Grads_images/sumRDPA/hrdpa/24/")
wxfiles<- list.files()
par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important

imager::load.image(wxfiles[length(wxfiles)]) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)

cat("  \n  \n  ")
imager::load.image(wxfiles[length(wxfiles)-2]) %>% imager::crop.borders(nx=0, ny=18) %>% plot(axes=FALSE)


```

```{r Meteograms, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8.8, fig.width=7.5, results='asis'}
if (meteogram==TRUE){
  cat("  \n# Weather forecast(s)  \n")

  stationCoords <- sf::st_as_sf(stationInfo, coords=c("Longitude", "Latitude"), crs=4326) %>% 
    sf::st_set_crs(4326) %>%
    sf::st_transform(3579)
  
  meteoStns <- sf::st_as_sf(dplyr::filter(data$spatial_stns[,c(1,3,7,8)], Type == "Meteogram"), coords=c("Longitude", "Latitude"), crs=4326) %>%
    sf::st_set_crs(4326) %>%
    sf::st_transform(3579)
  
  buffers <- sf::st_buffer(stationCoords, dist = 120000) #150 km buffer
  
  meteos <- as.data.frame(meteoStns[lengths(sf::st_intersects(meteoStns, buffers)) > 0,]) #subset meteoStns according to the meteoStns that return TRUE for intersection
  
  
# plot <- ggplot() +
#   geom_sf(data=stationCoords, col="red") +
#   geom_sf(data=meteoStns, col="blue") +
#   geom_sf(data=buffers, fill=NA) +
#   theme_minimal()

  dateTimeUTC <- format(Sys.time(), "%Y%m%d")

  par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
  
  for (i in meteos$Meteogram.code) {
    cat("  \n")
    imager::load.image(paste0("https://collaboration.cmc.ec.gc.ca/cmc/ensemble/data2/combine/images/", dateTimeUTC, "00_054@007_E1_", i, "_I_NAEFS@EPSGRAMS_tt@surf@nt@pr@ws@surf_360.png")) %>% plot(axes=FALSE)
    cat("  \n")
  }
}

```

\newpage

```{r Fixed camera images, eval=TRUE, echo=FALSE, fig.height=4, fig.width=7, message=FALSE, warning=FALSE, fig.height=4, fig.width=7, results='asis'}
#This section will contain auto-generated images, selected based on the stations(s) selected.

tryCatch({
  images <- XML::readHTMLTable(httr::content(httr::GET("https://collaboration.cmc.ec.gc.ca/cmc/hydrometric_additionalData/FieldData/YT/", config=httr::authenticate(Sys.getenv("ECCCUSER"), Sys.getenv("ECCCPASS"))), "text"))[[1]]
images <- images[c(-1,-2),-1] #first two rows are not files and first column is nothing
images <- images[grep(paste(stations, collapse="|"), images$Name), ] #subset only the images that match stations requested 

if (nrow(images)>=1){
  images <- dplyr::arrange(images, desc(images$`Last modified`)) %>% dplyr::mutate(Station = substr(Name, 1,7))
  
  par(mar=c(0,0,0,0)) #sets the plot margins to 0 - important
  cat("# Fixed Camera Images")
  for (i in unique(images$Station)){
    last_image <- dplyr::filter(images, Station==i)[1,]
    cat("  \n### ", stringr::str_to_title(hy_stations(i)$STATION_NAME), "(", substr(as.character(as.POSIXct(last_image[,2], tz="UTC")-7*60*60), 1, 16), "Yukon Time)  \n")
    
    
    temp <- paste0(tempfile(),".jpg")
    R.utils::downloadFile(paste0("https://collaboration.cmc.ec.gc.ca/cmc/hydrometric_additionalData/FieldData/YT/", last_image[,1]), temp, username=Sys.getenv("ECCCUSER"), password = Sys.getenv("ECCCPASS"))
    imager::load.image(paste0(temp)) %>% plot(axes=FALSE)
    unlink(temp)
    cat("  \n")
  }
}
}, error=function(e){cat("Fetching images failed. Do you have login credentials in your .Renviron file? Check the function notes for details.")})


```

```{r User select images, echo=FALSE, fig.height=4, fig.width=7, message=FALSE, warning=FALSE, results='asis'}
#This section will contain images in a folder specified by the user, if applicable
if (is.null(image_path)!=TRUE){
  cat("  \n# Other Images  \n")
  custom_images <- list.files(path-image_path)
  for (i in custom_images){
    imager::load.image(i) %>% plot(axes=FALSE)
    cat("  \n")
  }
}

```
